# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pcxUNTuB0cTHuqW-81jbafmS7cTgQkVW
"""

import numpy as np
from scipy.signal import convolve2d
from scipy.spatial.distance import cdist
import cv2 as cv
import matplotlib.pyplot as plt
from time import time
from skimage.feature import plot_matches
from skimage.transform import pyramid_gaussian

def get_nms_kp(V, kp_map, near_kp_count):
    fewer_kps = []
    for [col, row] in kp_map:
        # окно в пределах которого будут сравниваться значения пикселей с итер
        window = V[row - near_kp_count:row + near_kp_count + 1, col - near_kp_count:col + near_kp_count + 1]
        # нахожнение наибольшего в окне
        loc_row_col = np.unravel_index(window.argmax(), window.shape)
        # приведение к реальным координатам
        col_new = col + loc_row_col[1] - near_kp_count
        row_new = row + loc_row_col[0] - near_kp_count
        new_kp = [col_new, row_new]
        if new_kp not in fewer_kps:
            fewer_kps.append(new_kp)
    return fewer_kps

def FAST(img, N=9, threshold=0.15):
    kernel = np.array([[1, 2, 1],
                       [2, 4, 2],
                       [1, 2, 1]]) / 16 
    img = convolve2d(img, kernel, mode='same')
    # для окружности в 3 пикселя из алгоритма Брезенхема
    circle_idx = np.array([[3, 3, 2, 1, 0, -1, -2, -3, -3, -3, -2, -1, 0, 1, 2, 3],
                           [0, 1, 2, 3, 3, 3, 2, 1, 0, -1, -2, -3, -3, -3, -2, -1]])
    cross_idx = np.array([[3, 0, -3, 0], [0, 3, 0, -3]])

    nms_V_func = np.zeros(img.shape)
    keypoints = []
    for row in range(3, img.shape[0] - 3):
        for col in range(3, img.shape[1] - 3):
            Ip = img[row, col]
            # пороговая величина
            # 15% от интенсивности выбранного пикселя
            t = threshold * Ip if threshold < 1 else threshold
            # проверка 1, 5, 9 и 13 пикселей
            # проверка интенсивности Ip±t
            current_I_fast = img[row + cross_idx[0, :], col + cross_idx[1, :]]
            if np.count_nonzero(Ip + t < current_I_fast) >= 3 or np.count_nonzero(Ip - t > current_I_fast) >= 3:
                # проверка всех пикселей на окружности
                current_I_full = img[row + circle_idx[0, :], col + circle_idx[1, :]]
                if np.count_nonzero(current_I_full >= Ip + t) >= N or np.count_nonzero(current_I_full <= Ip - t) >= N:
                    # добавление ключевой точки
                    keypoints.append([col, row])  # keypoint = [col, row]
                    nms_V_func[row, col] = np.sum(np.abs(Ip - current_I_full))  # NMS
    fewer_kps = keypoints
    return np.array(fewer_kps)

def find_centroid(img, corners, mask, mask_r, mask_c, middle_r, middle_c):
    teta = []
    for i in range(corners.shape[0]):
        c0, r0 = corners[i, :]
        m01, m10 = 0, 0  # равны нулю при grayscale
        for r in range(mask_r):
            m01_temp = 0
            for c in range(mask_c):
                if mask[r, c]:
                    I = img[r0 + r, c0 + c]  # интенсивность элементов маски
                    m10 = m10 + I * (c - middle_c)
                    m01_temp = m01_temp + I
            m01 = m01 + m01_temp * (r - middle_r)
        teta.append(np.arctan2(m01, m10))
    return np.array(teta)

def get_intensity_centroind(img, corners):
    # создание маски окна ключевой точки для дальнейшего вычисления центроида
    orientation_mask = np.zeros((31, 31), dtype=np.int32)
    # kp_pose = [15, 15]
    u_max = [15, 15, 15, 15, 14, 14, 14, 13, 13, 12, 11, 10, 9, 8, 6, 3]
    for i in range(-15, 16):
        for j in range(-u_max[abs(i)], u_max[abs(i)] + 1):
            orientation_mask[15 + j, 15 + i] = 1
            # orientation_mask[map(sum, zip(kp_pose, [j, i]))]
    mask_r, mask_c = orientation_mask.shape
    middle_r = (mask_r - 1) // 2
    middle_c = (mask_c - 1) // 2
    img = np.pad(img, (middle_r, middle_c), mode='constant', constant_values=0)
    try:
        return find_centroid(img, corners, orientation_mask, mask_r, mask_c, middle_r, middle_c)
    except Exception:
        print('!!!!SOMETHING IN CENTROID OR-TION!!!!')

def BRIEF(img, keypoints, orientations=None, n=256, patch_size=9, sigma=1, mode='uniform', sample_seed=42):
    random = np.random.RandomState(seed=sample_seed)
    kernel = np.array([[1, 4, 7, 4, 1],
                       [4, 16, 26, 16, 4],
                       [7, 26, 41, 26, 7],
                       [4, 16, 26, 16, 4],
                       [1, 4, 7, 4, 1]]) / 273  # 5x5 Окно Гаусса
    img = convolve2d(img, kernel, mode='same')
    if mode == 'uniform':
        # генерация пар координат пикселей в рабочей зоне в массив dim[2,2]
        samples = random.randint(-(patch_size - 2) // 2 + 1, (patch_size // 2), (n * 2, 2))
        samples = np.array(samples, dtype=np.int32)
        # каждый набор - массив пикселей x,y из тестовых пикселей
        pos1, pos2 = np.split(samples, 2)  # делит на два np размерностью n,2
    rows, cols = img.shape
    mask = (((patch_size // 2 - 1) < keypoints[:, 0])
            & (keypoints[:, 0] < (cols - patch_size // 2 + 1))
            & ((patch_size // 2 - 1) < keypoints[:, 1])
            & (keypoints[:, 1] < (rows - patch_size // 2 + 1)))
    # тип данных индекс
    keypoints = np.array(keypoints[mask, :], dtype=np.intp, copy=False)
    descriptors = np.zeros((keypoints.shape[0], n), dtype=bool)  # карта дескриптора
    # итерация по количеству пар тестовых пикселей
    for p in range(pos1.shape[0]):  # количество пар
        pr0 = pos1[p, 0]  # row
        pc0 = pos1[p, 1]  # col
        pr1 = pos2[p, 0]
        pc1 = pos2[p, 1]
        # сопоставление первого тестового пикселя и
        for k in range(keypoints.shape[0]):
            # нахождение координат ключевой точки, к которой привязан патч
            # позволяет получить интенсивность тестового пикселя из реального изображения
            kr = keypoints[k, 1]
            kc = keypoints[k, 0]
            if img[kr + pr0, kc + pc0] < img[kr + pr1, kc + pc1]:
                descriptors[k, p] = True  # 0 или 1
    return descriptors  # вернёт таблицу True/False

def match(descriptors1, descriptors2, max_distance=np.inf, cross_check=True, distance_ratio=None):
    distances = cdist(descriptors1, descriptors2, metric='hamming')

    indices1 = np.arange(descriptors1.shape[0])
    indices2 = np.argmin(distances, axis=1)
    if cross_check:
        matches1 = np.argmin(distances, axis=0)
        mask = indices1 == matches1[indices2]  
        indices1 = indices1[mask]
        indices2 = indices2[mask]

    if max_distance < np.inf:
        mask = distances[indices1, indices2] < max_distance
        indices1 = indices1[mask]
        indices2 = indices2[mask]

    if distance_ratio is not None:
        modified_dist = distances
        fc = np.min(modified_dist[indices1, :], axis=1)
        modified_dist[indices1, indices2] = np.inf
        fs = np.min(modified_dist[indices1, :], axis=1)
        mask = fc / fs <= 0.5
        indices1 = indices1[mask]
        indices2 = indices2[mask]
    dist = distances[indices1, indices2]
    sorted_indices = dist.argsort()

    matches = np.column_stack((indices1[sorted_indices], indices2[sorted_indices]))
    return matches

def figure_image(grays, img):
    plt.figure()
    plt.subplot(1, 2, 1)
    plt.imshow(grays, cmap='gray')
    plt.subplot(1, 2, 2)
    plt.imshow(img)

img1 = cv.imread('/content/geom_obj_1.jpg')
original_img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)
img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)
gray1 = cv.cvtColor(img1, cv.COLOR_RGB2GRAY)
grays1 = list(pyramid_gaussian(gray1, downscale=2, max_layer=4, multichannel=False))

img2 = cv.imread('/content/geom_obj_2.jpg')
original_img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)
img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)
gray2 = cv.cvtColor(img2, cv.COLOR_RGB2GRAY)
grays2 = list(pyramid_gaussian(gray2, downscale=2, max_layer=4, multichannel=False))

scales = [(i * 2 if i > 0 else 1) for i in range(4)]
features_img1 = np.copy(img1)
features_img2 = np.copy(img2)

kps1, kps2 = [], []
ds1, ds2 = [], []
ms = []

scale_kp1 = FAST(grays1[0], N=9, threshold=0.15)
kps1.append(scale_kp1 * scales[0])
for keypoint in scale_kp1:
    features_img1 = cv.circle(features_img1, 
                                tuple(keypoint * scales[0]), 
                                3 * scales[0], (255, 0, 0), 1)
    
scale_kp2 = FAST(grays2[0], N=9, threshold=0.15)
kps2.append(scale_kp2 * scales[0])
for keypoint in scale_kp2:
    features_img2 = cv.circle(features_img2, tuple(keypoint * scales[0]), 3 * scales[0], (255, 0, 0), 1)
figure_image(grays1[0], features_img1)
figure_image(grays2[0], features_img2)
print('Количество ключевых точек на первом кадре: ', scale_kp1.shape[0])
print('Количество ключевых точек на втором кадре: ', scale_kp2.shape[0])
plt.show()

d1 = BRIEF(grays1[0], scale_kp1, mode='uniform', patch_size=8, n=512)
ds1.append(d1)
d2 = BRIEF(grays2[0], scale_kp2, mode='uniform', patch_size=8, n=512)
ds2.append(d2)

matches = match(d1, d2, cross_check=True)
ms.append(matches)
print('Количество совпадений: ', matches.shape[0])

fig = plt.figure(figsize=(20, 10))
ax = fig.add_subplot(1, 1, 1)

plot_matches(ax, grays1[0], grays2[0], 
                np.flip(scale_kp1, 1), 
                np.flip(scale_kp2, 1), 
                matches)
plt.show()